{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A fonte de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escolhi a fonte de dados abertos da CVM contendo a cotação diária dos fundos de investimentos negociados no mercado brasileiro. Essa fonte é atualizada diariamente com os dados de fechamento do dia anterior e as contações são agrupadas por arquivos correspondentes a cada mês do ano.\n",
    "\n",
    "Esse é um cenário bem comum em fontes de dados abertas, uma série de arquivos no formato CSV agrupapando informações de acordo com a data, então  a solução que vamos implementar durante o tutorial é reaproveitável para outras fontes de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro é importante analisar a fonte de dados, entender como ela está estruturada, quais campos compõem o dataset e como nós podemos automatizar a coleta dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fonte de dados contendo a cotação diária dos fundos pode ser acessada através do [portal de dados abertos](http://www.dados.gov.br) pelo link:\n",
    "\n",
    "[http://www.dados.gov.br/dataset/fi-doc-inf_diario](http://www.dados.gov.br/dataset/fi-doc-inf_diario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui tem uma descrição rápida sobre as informações que existem no dataset:\n",
    "![](img/descricao_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além de um link para o recurso contendo o dicionário de dados que descreve cada campo do dataset, é **sempre muito importante analisar o dicionário de dados do dataset, se disponível.** Não vou entrar em detalhes sobre as descrições do dicionário para não estender o tutorial, mas sugiro que você olhe para ser familiarizar com esse tipo de formato.\n",
    "\n",
    "![](img/link_dicionario.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como automatizar o download "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora partindo para como nós podemos automatizar a extração dos datasets, como podemos observar no site existe um link para todos os datasets dos últimos 12 meses. Primeiro precisamos analisar se existe um padrão nas urls de download dos arquivos, para isso vamos copiar alguns endereços e compará-los.\n",
    "\n",
    "Para copiar os endereços clique com o botão direito no botão **\"Ir para recurso\"** e selecione a opção **\"Copiar link\"**:\n",
    "\n",
    "![](img/link_recurso.png)\n",
    "\n",
    "Copiei três links e vamos compará-los a seguir:\n",
    "\n",
    "[http://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_201907.csv](http://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_201907.csv)\n",
    "\n",
    "[http://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_201910.csv](http://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_201910.csv)\n",
    "\n",
    "[http://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202003.csv](http://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202003.csv)\n",
    "\n",
    "Como podemos observar existe um padrão claro nos links:`dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_YYYYMM.csv`. A única variação é o mês e o ano de referência do dataset. Com essa análise nossa tarefa de automatizar o download dos datasets ficou mais simples, porque agora podemos gerar sistematicamente o intervalo de datas que queremos baixar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo de extração consiste nesse caso em fazer o download de todos os arquivos da janela de tempo q nos interessa. Mas precisamos visualizar todas as etapas que precisam ser completadas até que seja possível fazer o download desses arquivos:\n",
    "\n",
    "1. Automatizar a geração do nome dos arquivos: já que a única coisa que varia nos links é o nome dos arquivos precisamos automatizar a geração desses nomes de acordo com a janela de tempo do nosso interesse;\n",
    "\n",
    "2. Requisitar o arquivo: precisamos enviar uma requisição para o portal de dados abertos do arquivo que queremos fazer o download;\n",
    "\n",
    "3. Salvar arquivo: o portal de dados abertos vai nos enviar o arquivo requisitado e precisamos salvá-lo no nosso computador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente vamos criar uma função para facilitar a criação da lista de datas que nós queremos baixar do site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dates(initial_date, final_date, increment, format):\n",
    "    \"\"\"\n",
    "    Função para gerar uma lista de datas no formato string.\n",
    "    \n",
    "    Parâmetros:\n",
    "        initial_date = Data inicial da contagem;\n",
    "        \n",
    "        final_date = Data final da contagem;\n",
    "        \n",
    "        increment = Quanto deve ser incrementado da data, em dias, para cada iteração;\n",
    "        \n",
    "        format = Formato da data de saída obedecendo os códigos disponíveis na documentação do python:\n",
    "                 https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\n",
    "    \"\"\"\n",
    "    date_list = []\n",
    "    \n",
    "    while initial_date < final_date:\n",
    "        date_list.append(initial_date.strftime(format))\n",
    "        initial_date = initial_date + timedelta(days=increment)\n",
    "        \n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo a requisição e salvando os arquivos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos trabalhar agora com a biblioteca python [requests](https://requests.readthedocs.io/en/master/) que facilita a implementação de requisições HTTP, que é essencialmente o tipo de requisição que precisamos fazer para baixar os arquivos da nossa fonte de dados. \n",
    "\n",
    "Para fazer a requisição utilizaremos o méodo `requests.get()` que recebe como primeiro parâmetro a URL que queremos requisitar, podemos então checar se ocorreu algum erro através do [_status code_](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status) da resposta, o _status code_ `200` significa que a requisição foi bem sucedida. No fim, o conteúdo da resposta pode ser acessado através do atributo `.content`. Recomendo explorar a excelente [documentação da biblioteca](https://requests.readthedocs.io/en/latest/) caso queira conhecer melhor.\n",
    "\n",
    "```python\n",
    ">>> import requests\n",
    "\n",
    ">>> response = requests.get(url)\n",
    "\n",
    ">>> response.content\n",
    "b\"Conteúdo da página\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(dates, file_base_name='inf_diario_fi', dir='data/'):\n",
    "    \"\"\"\n",
    "    Função para fazer o download de todos os arquivos das datas disponibilizadas.\n",
    "    \n",
    "    Parâmetros:\n",
    "        dates = Lista de datas;\n",
    "        \n",
    "        file_base_name = Nome base para os arquivos que serão salvos;\n",
    "        \n",
    "        dir = Diretório onde os arquivo serão salvos.\n",
    "    \"\"\"\n",
    "    saved_files = []\n",
    "    # URL base para baixar os arquivos\n",
    "    base_url = \"http://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS\"\n",
    "    \n",
    "    for date in dates:\n",
    "        # Contrói a URL de download do arquivo a partir da data\n",
    "        url = \"{}/inf_diario_fi_{}.csv\".format(base_url, date)\n",
    "        \n",
    "        # Realiza a requisição\n",
    "        response = requests.get(url)\n",
    "                \n",
    "        if response.status_code != 200:\n",
    "            print(\"Erro ao requisitar o arquivo {}\".format(url))\n",
    "            \n",
    "            # Caso ocorra um erro durante a requisição pular para a próxima data\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        file_name = \"{}{}_{}.csv\".format(dir, file_base_name, date)\n",
    "        \n",
    "        # Salva o arquivo\n",
    "        with open(file_name, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        saved_files.append(file_name)\n",
    "        print('Arquivo {} salvo.'.format(file_name))\n",
    "    \n",
    "    return saved_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos prontos agora para fazer o download dos arquivos, vamos definir duas variáveis para a data inicial e final do período que queremos extrair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_date = datetime(year=2019, month=5, day=1)\n",
    "final_date = datetime(year=2020, month=4, day=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a função `generate_dates` vamos gerar a lista de datas do período definido. Precisamos passar a data inicial e final, o quanto queremos incrementar em dias para cada iteração, nesse caso como nossa fonte de dados tem um arquivo por mês devemos incrementar 31 dias a cada iteração. Como último parametrô a função recebe o formato da data de saída, devemos utilizar os [códigos de formatação descritos na documentação do Python](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes) para construir a data no formato que queremos, na fonte de dados a data dos arquivos está no formato: YYYYMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = generate_dates(initial_date, final_date, 31, \"%Y%m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['201905', '201906', '201907', '201908', '201909', '201910', '201911', '201912', '202001', '202002', '202003', '202004']\n"
     ]
    }
   ],
   "source": [
    "print(date_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos execuar a função de download dos arquivos e assistir a magia acontecer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo data/inf_diario_fi_201905.csv salvo.\n",
      "Arquivo data/inf_diario_fi_201906.csv salvo.\n",
      "Arquivo data/inf_diario_fi_201907.csv salvo.\n",
      "Arquivo data/inf_diario_fi_201908.csv salvo.\n",
      "Arquivo data/inf_diario_fi_201909.csv salvo.\n",
      "Arquivo data/inf_diario_fi_201910.csv salvo.\n",
      "Arquivo data/inf_diario_fi_201911.csv salvo.\n",
      "Arquivo data/inf_diario_fi_201912.csv salvo.\n",
      "Arquivo data/inf_diario_fi_202001.csv salvo.\n",
      "Arquivo data/inf_diario_fi_202002.csv salvo.\n",
      "Arquivo data/inf_diario_fi_202003.csv salvo.\n",
      "Arquivo data/inf_diario_fi_202004.csv salvo.\n"
     ]
    }
   ],
   "source": [
    "file_list = download_files(date_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de entrar na etapa de tratamente é importante que você explore os dados para assim conseguir identificar exatamente quais transformações você deseja aplicar, se é necessário tratar algum campo ou filtrar alguma informação. Não vou demonstrar a etapa de análise pois é necessário um tutorial dedicado somente a esclarecer essa fase. Vamos partir do pressuposto que é necessário realizar as seguintes atividades:\n",
    "\n",
    "1. Juntar todos os arquivos em um só;\n",
    "2. Remover os caracteres especiais do CNPJ;\n",
    "3. Manter somente as colunas: `CNPJ_FUNDO`, `VL_QUOTA`, `DT_COMPTC`, `VL_PATRIM_LIQ` e `NR_COTST`.\n",
    "\n",
    "Daqui para frente vamos utilizar principalmente a biblioteca [Pandas](https://pandas.pydata.org/), que oferece uma série de ferramentas para facilitar a manipulação e análise de dados. O Pandas oferece uma estrutura de dados tabular chamada [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) que permite carregar dados de diferentes formatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntando todos arquivos em um"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar a função [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) do pandas para ler os arquivos baixados e a função [concat](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html?highlight=concat#pandas-concat) para juntá-los em um só [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html). É importante observar que o separador dos arquivos `csv` baixados não é a vírgula(`,`) e sim o ponto e vírgula(`;`), é necessário especificar essa informação ao ler o arquivo usando a função [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). O jeito mais rápido de descobrir qual é o separador de um arquivo `csv` é abrindo-o como um arquivo de texto através de um editor de texto, é possível observar qual o separador utilizado no conteúdo do arquivo.\n",
    "\n",
    "Vamos então criar uma função para concatenar todos os arquivos lidos em um só [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_csvs(files, sep=','):\n",
    "    \"\"\"\n",
    "    Concatena todos os arquivos em um só DataFrame\n",
    "    \n",
    "    Parâmetros:\n",
    "        files = Lista do nome e caminho dos arquivos a serem concatenados;\n",
    "        sep = Separador dos arquivos csv's.\n",
    "    \"\"\"\n",
    "    # Gera uma lista onde cada DataFrame é um item da lista\n",
    "    df_list = [pd.read_csv(file, sep=sep) for file in files]\n",
    "    \n",
    "    # Concatena todos os itens da lista em um só DataFrame\n",
    "    df = pd.concat(df_list)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos aproveitar da capacidade do Jupyter Notebook de executar [comandos shell](https://www.geeksforgeeks.org/basic-shell-commands-in-linux/) para listar todos os arquivos salvos no diretório `data/` e armazenar o resultado em uma variável:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = !ls -d data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/inf_diario_fi_201905.csv', 'data/inf_diario_fi_201906.csv', 'data/inf_diario_fi_201907.csv', 'data/inf_diario_fi_201908.csv', 'data/inf_diario_fi_201909.csv', 'data/inf_diario_fi_201910.csv', 'data/inf_diario_fi_201911.csv', 'data/inf_diario_fi_201912.csv', 'data/inf_diario_fi_202001.csv', 'data/inf_diario_fi_202002.csv', 'data/inf_diario_fi_202003.csv', 'data/inf_diario_fi_202004.csv']\n"
     ]
    }
   ],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos executar a função `concat_csvs` para gerar nosso [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) resultante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_csvs(files, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de linhas do DataFrame: 4105029\n",
      "Quantidade de colunas do DataFrame: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantidade de linhas do DataFrame: {}\".format(df.shape[0]))\n",
    "print(\"Quantidade de colunas do DataFrame: {}\".format(df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do DataFrame: ['CNPJ_FUNDO' 'DT_COMPTC' 'VL_TOTAL' 'VL_QUOTA' 'VL_PATRIM_LIQ'\n",
      " 'CAPTC_DIA' 'RESG_DIA' 'NR_COTST']\n"
     ]
    }
   ],
   "source": [
    "print(\"Colunas do DataFrame: {}\".format(df.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo caracteres especiais do CNPJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
